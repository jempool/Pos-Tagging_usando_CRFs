{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pos_tagging2_version_4_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tMRragjvkU4J"
      },
      "source": [
        "## Python Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XcHO9PljuZHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "d9aaedab-27ba-48f0-cf60-e5250ea34490"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras as k\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Input, load_model\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "from keras_contrib.layers import CRF\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "!pip install seqeval\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from tkinter import *\n",
        "from tkinter.ttk import *\n",
        "from prettytable import PrettyTable\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-czdyblq6\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-czdyblq6\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=abc02d2fafeee73cd5c3e07e07f1d2f124d26c0d04b68440194fe4b6402aac95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uxwu31co/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=8a317d5b805f57948384591a3a5a19e7be4831a4c5481cbb1028b73f85621ce5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnO94rlfuZIL"
      },
      "source": [
        "## Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ahWEusT1Zy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d5d10907-e534-41e7-fb8e-cab8fad41421"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "097oMpQ2kU4j"
      },
      "source": [
        "## Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6HLjgn9ikU4l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "00910ff3-a17d-4b02-bf85-4851b1384017"
      },
      "source": [
        "nltk.download('cess_esp')\n",
        "from nltk.corpus import cess_esp\n",
        "\n",
        "tagged_sentences = cess_esp.tagged_sents()\n",
        "\n",
        "print(\"\\n\", tagged_sentences[0], \"\\n\")\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "print(\"Tagged words:\", len(cess_esp.tagged_words()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cess_esp.zip.\n",
            "\n",
            " [('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')] \n",
            "\n",
            "Tagged sentences:  6030\n",
            "Tagged words: 192685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S7qhFY6quZIz"
      },
      "source": [
        "## Sample of the arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhQ_o1RruZI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "dcdbd430-2d33-42d0-d0a3-6a5b5f6fad67"
      },
      "source": [
        "# Split sentences and tags into two different arrays\n",
        "sentences, tagss = [], []\n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    tagss.append(np.array(tags))\n",
        "    sentences.append(np.array(sentence))\n",
        "\n",
        "# Custom function for print a sentence\n",
        "def goodPrint(a):\n",
        "    x = \"\"\n",
        "    for i in range(len(a)):\n",
        "        x += a[i]+\" \"\n",
        "    return x\n",
        "\n",
        "print(str(len(sentences)) + \" sentences\\n\")\n",
        "print(str(len(sentences[0])) + \" words in the first sentence\\n\")\n",
        "print(goodPrint(sentences[0])+ \"\\n\")\n",
        "print(str(len(tagss[0])) +\" tags in the first sentence\\n\" )\n",
        "print(tagss[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6030 sentences\n",
            "\n",
            "40 words in the first sentence\n",
            "\n",
            "El grupo estatal Electricité_de_France -Fpa- EDF -Fpt- anunció hoy , jueves , la compra del 51_por_ciento de la empresa mexicana Electricidad_Águila_de_Altamira -Fpa- EAA -Fpt- , creada por el japonés Mitsubishi_Corporation para poner_en_marcha una central de gas de 495 megavatios . \n",
            "\n",
            "40 tags in the first sentence\n",
            "\n",
            "['da0ms0' 'ncms000' 'aq0cs0' 'np00000' 'Fpa' 'np00000' 'Fpt' 'vmis3s0'\n",
            " 'rg' 'Fc' 'W' 'Fc' 'da0fs0' 'ncfs000' 'spcms' 'Zp' 'sps00' 'da0fs0'\n",
            " 'ncfs000' 'aq0fs0' 'np00000' 'Fpa' 'np00000' 'Fpt' 'Fc' 'aq0fsp' 'sps00'\n",
            " 'da0ms0' 'aq0ms0' 'np00000' 'sps00' 'vmn0000' 'di0fs0' 'ncfs000' 'sps00'\n",
            " 'ncms000' 'sps00' 'Z' 'ncmp000' 'Fp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ACHtdEPRuZI6"
      },
      "source": [
        "## Percentages for training, testing and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7OizRh02uZI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "5928b099-d9c9-4ebc-b062-f7812259335b"
      },
      "source": [
        "(training_sentences, \n",
        " test_sentences, \n",
        " training_tags, \n",
        " test_tags) = train_test_split(sentences, tagss, test_size=0.2)\n",
        "\n",
        "(train_sentences, \n",
        " eval_sentences, \n",
        " train_tags, \n",
        " eval_tags) = train_test_split(training_sentences, training_tags, test_size=0.25)\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(str(len(train_sentences)), \" sentences for training (60%)\")\n",
        "print(str(len(test_sentences)), \" sentences for testing (20%)\")\n",
        "print(str(len(eval_sentences)), \" sentences for evaluating (20%)\\n\")\n",
        "\n",
        "print(\"first sentence for training (\",len(train_sentences[0]) , \" words )\\n\", train_sentences[0])\n",
        "print(\"\\nfirst sentence for testing (\",len(test_sentences[0]) , \" words )\\n\", test_sentences[0])\n",
        "print(\"\\nfirst sentence for evaluating (\",len(eval_sentences[0]) , \" words )\\n\", eval_sentences[0])\n",
        "\n",
        "print(\"\\n---------------------------------------------------------------------------\\n\")\n",
        "\n",
        "print(str(len(train_tags)), \" tags for training (60%)\")\n",
        "print(str(len(test_tags)), \" tags for testing (20%)\")\n",
        "print(str(len(eval_tags)), \" tags for evaluating (20%)\\n\")\n",
        "\n",
        "print(\"first tag for training  (\",len(train_tags[0]) , \" tags )\\n\", train_tags[0])\n",
        "print(\"\\nfirst tag for testing (\",len(test_tags[0]) , \" tags )\\n\", test_tags[0])\n",
        "print(\"\\nfirst tag for evaluating (\",len(eval_tags[0]) , \" tags )\\n\", eval_tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "3618  sentences for training (60%)\n",
            "1206  sentences for testing (20%)\n",
            "1206  sentences for evaluating (20%)\n",
            "\n",
            "first sentence for training ( 25  words )\n",
            " ['En' '1926' 'las' 'fábricas' 'de' 'Daimler' 'y' 'de' 'Benz' ',' 'que'\n",
            " 'nunca' 'se' 'conocieron' 'personalmente' ',' 'se' 'reúnen' 'en' 'una'\n",
            " 'sola' ',' 'la' 'DaimlerBenz_A._G.' '.']\n",
            "\n",
            "first sentence for testing ( 44  words )\n",
            " ['Fuentes' 'del' 'sector' 'crítico' 'de' 'CDC' ',' 'opinan' 'que' 'el' '\"'\n",
            " 'golpe' 'de' 'efecto' '\"' 'de' 'Esteve' 'ha' 'sorprendido'\n",
            " 'favorablemente' ',' 'ya_que' '*0*' 'reconduce' 'la' 'situación'\n",
            " 'interna' 'hacia' 'un' 'nuevo' 'escenario' 'en' 'el' 'que' 'se' 'pueden'\n",
            " 'conciliar' 'mejor' 'las' 'distintas' 'sensibilidades' 'del' 'partido'\n",
            " '.']\n",
            "\n",
            "first sentence for evaluating ( 20  words )\n",
            " ['De' 'toda' 'la' 'serie' 'sacó' 'Ford' 'la' 'experiencia' 'de' 'su'\n",
            " 'vida' ':' 'la' 'gente' 'prefería' 'autos' 'sólidos' 'y' 'baratos' '.']\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "3618  tags for training (60%)\n",
            "1206  tags for testing (20%)\n",
            "1206  tags for evaluating (20%)\n",
            "\n",
            "first tag for training  ( 25  tags )\n",
            " ['sps00' 'W' 'da0fp0' 'ncfp000' 'sps00' 'np0000p' 'cc' 'sps00' 'np0000p'\n",
            " 'Fc' 'pr0cn000' 'rg' 'pp3cn000' 'vmis3p0' 'rg' 'Fc' 'p0000000' 'vmip3p0'\n",
            " 'sps00' 'pi0fs000' 'aq0fs0' 'Fc' 'da0fs0' 'np0000o' 'Fp']\n",
            "\n",
            "first tag for testing ( 44  tags )\n",
            " ['ncfp000' 'spcms' 'ncms000' 'aq0ms0' 'sps00' 'np0000o' 'Fc' 'vmip3p0'\n",
            " 'cs' 'da0ms0' 'Fe' 'ncms000' 'sps00' 'ncms000' 'Fe' 'sps00' 'np0000p'\n",
            " 'vaip3s0' 'vmp00sm' 'rg' 'Fc' 'cs' 'sn.e-SUJ' 'vmip3s0' 'da0fs0'\n",
            " 'ncfs000' 'aq0fs0' 'sps00' 'di0ms0' 'aq0ms0' 'ncms000' 'sps00' 'da0ms0'\n",
            " 'pr0cn000' 'p0000000' 'vmip3p0' 'vmn0000' 'rg' 'da0fp0' 'di0fp0'\n",
            " 'ncfp000' 'spcms' 'ncms000' 'Fp']\n",
            "\n",
            "first tag for evaluating ( 20  tags )\n",
            " ['sps00' 'di0fs0' 'da0fs0' 'ncfs000' 'vmis3s0' 'np0000p' 'da0fs0'\n",
            " 'ncfs000' 'sps00' 'dp3cs0' 'ncfs000' 'Fd' 'da0fs0' 'ncfs000' 'vmii3s0'\n",
            " 'ncmp000' 'aq0mp0' 'cc' 'aq0mp0' 'Fp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHecruQluZJK"
      },
      "source": [
        "## Word and tag dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jLlvGcXpuZJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "143fde92-edda-4191-a296-4535e2b4e149"
      },
      "source": [
        "words, tagsss = set([]), set([])\n",
        " \n",
        "for s in (train_sentences + eval_sentences + test_sentences):\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        "\n",
        "for ts in (train_tags + eval_tags + test_tags):\n",
        "    for t in ts:\n",
        "        tagsss.add(t)\n",
        "\n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        " \n",
        "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding\n",
        "tag2index['-OOV-'] = 1  # The special value used to OOVs\n",
        "\n",
        "print (\"\\nWord dictionary length: \", len(word2index))\n",
        "print (\"Tag dictionary length: \", len(tag2index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Word dictionary length:  24499\n",
            "Tag dictionary length:  291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R6qh3so4uZJR"
      },
      "source": [
        "## Parsing Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YcKOFMa4uZJS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "693a727a-a369-4137-8373-8397eb7b55be"
      },
      "source": [
        "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
        "\n",
        "for s in train_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)\n",
        "\n",
        "for s in eval_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    eval_sentences_X.append(s_int)\n",
        "\n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        "\n",
        "for s in train_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    train_tags_y.append(s_int)\n",
        "\n",
        "for s in eval_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    eval_tags_y.append(s_int)\n",
        "\n",
        "for s in test_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    test_tags_y.append(s_int)\n",
        "\n",
        "\n",
        "print(\"\\n--------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"\\nfirst parsed sentence for training (\", len(train_sentences_X[0]),\" words )\\n\\n\", train_sentences_X[0])\n",
        "print(\"\\ntags of the first parsed sentence for training (\", len(train_tags_y[0]),\" tags )\\n\\n\", train_tags_y[0])\n",
        "print(\"\\n--------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"\\nfirst parsed sentence for testing (\", len(test_sentences_X[0]),\" words )\\n\\n\", test_sentences_X[0])\n",
        "print(\"\\ntags of the first parsed sentence for testing (\", len(test_tags_y[0]),\" tags )\\n\\n\", test_tags_y[0])\n",
        "print(\"\\n--------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"\\nfirst parsed sentence for evaluating (\", len(eval_sentences_X[0]),\" words )\\n\\n\", eval_sentences_X[0])\n",
        "print(\"\\ntags of the first parsed sentence for evaluating (\", len(eval_tags_y[0]),\" tags )\\n\\n\", eval_tags_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "first parsed sentence for training ( 25  words )\n",
            "\n",
            " [23539, 23356, 10898, 12409, 9799, 15248, 18910, 9799, 9990, 8366, 6782, 14330, 16359, 21989, 15199, 8366, 16359, 13980, 23539, 20273, 719, 8366, 18496, 19655, 22591]\n",
            "\n",
            "tags of the first parsed sentence for training ( 25  tags )\n",
            "\n",
            " [240, 239, 25, 229, 240, 232, 100, 240, 232, 178, 81, 185, 20, 289, 185, 178, 90, 92, 240, 64, 22, 178, 70, 45, 44]\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "first parsed sentence for testing ( 44  words )\n",
            "\n",
            " [12346, 4109, 5735, 16617, 9799, 5167, 8366, 1666, 6782, 4757, 1114, 515, 9799, 14063, 1114, 9799, 8134, 11401, 5361, 8560, 8366, 15569, 18548, 6163, 18496, 15897, 12064, 12239, 22658, 13043, 9878, 23539, 4757, 6782, 16359, 570, 8955, 10152, 10898, 19514, 11478, 4109, 13758, 22591]\n",
            "\n",
            "tags of the first parsed sentence for testing ( 44  tags )\n",
            "\n",
            " [229, 257, 207, 242, 240, 45, 178, 92, 175, 29, 164, 207, 240, 207, 164, 240, 232, 176, 18, 185, 178, 175, 69, 195, 70, 122, 22, 240, 39, 242, 207, 240, 29, 81, 90, 92, 101, 185, 25, 146, 229, 257, 207, 44]\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "first parsed sentence for evaluating ( 20  words )\n",
            "\n",
            " [9799, 19711, 18496, 6792, 17350, 4783, 18496, 2118, 9799, 24292, 3136, 12458, 18496, 10697, 21890, 7109, 3432, 18910, 899, 22591]\n",
            "\n",
            "tags of the first parsed sentence for evaluating ( 20  tags )\n",
            "\n",
            " [240, 65, 70, 122, 167, 232, 70, 122, 240, 210, 122, 209, 70, 122, 235, 86, 71, 100, 71, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mw78VGYxuZJp"
      },
      "source": [
        "## Normalization based on the longest sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HOCcNUJWuZJq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc3dfd04-ba86-4c30-e668-6458685f6cd3"
      },
      "source": [
        "MAX_LENGTH_TRAIN = len(max(train_sentences_X, key=len))\n",
        "MAX_LENGTH_EVAL = len(max(eval_sentences_X, key=len))\n",
        "MAX_LENGTH_TEST = len(max(test_sentences_X, key=len))\n",
        "\n",
        "print(\"\\nLongest sentence in training set -> \", MAX_LENGTH_TRAIN, \" words\")\n",
        "print(\"Longest sentence in evaluating set -> \", MAX_LENGTH_EVAL, \" words\")\n",
        "print(\"Longest sentence in testing set -> \", MAX_LENGTH_TEST, \" words\")\n",
        "\n",
        "MAX_LENGTH = max(MAX_LENGTH_TRAIN, MAX_LENGTH_EVAL, MAX_LENGTH_TEST)\n",
        "print(\"\\nLongest sentence in all sets -> \", MAX_LENGTH, \" words\\n\")\n",
        "print(\"-------------------------------------------------------------------------\\n\")\n",
        "\n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "print(\"first parsed and normalized sentence for training\\n\\n\", train_sentences_X[0])\n",
        "print(\"\\ntags\\n\\n\", train_tags_y[0])\n",
        "print(\"\\n-------------------------------------------------------------------------\\n\")\n",
        "print(\"first parsed and normalized sentence for evaluating\\n\\n\", eval_sentences_X[0])\n",
        "print(\"\\ntags\\n\\n\", eval_tags_y[0])\n",
        "print(\"\\n-------------------------------------------------------------------------\\n\")\n",
        "print(\"first parsed and normalized sentence for testing\\n\\n\", test_sentences_X[0])\n",
        "print(\"\\ntags\\n\\n\", test_tags_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Longest sentence in training set ->  134  words\n",
            "Longest sentence in evaluating set ->  149  words\n",
            "Longest sentence in testing set ->  95  words\n",
            "\n",
            "Longest sentence in all sets ->  149  words\n",
            "\n",
            "-------------------------------------------------------------------------\n",
            "\n",
            "first parsed and normalized sentence for training\n",
            "\n",
            " [23539 23356 10898 12409  9799 15248 18910  9799  9990  8366  6782 14330\n",
            " 16359 21989 15199  8366 16359 13980 23539 20273   719  8366 18496 19655\n",
            " 22591     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "\n",
            "tags\n",
            "\n",
            " [240 239  25 229 240 232 100 240 232 178  81 185  20 289 185 178  90  92\n",
            " 240  64  22 178  70  45  44   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n",
            "\n",
            "-------------------------------------------------------------------------\n",
            "\n",
            "first parsed and normalized sentence for evaluating\n",
            "\n",
            " [ 9799 19711 18496  6792 17350  4783 18496  2118  9799 24292  3136 12458\n",
            " 18496 10697 21890  7109  3432 18910   899 22591     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "\n",
            "tags\n",
            "\n",
            " [240  65  70 122 167 232  70 122 240 210 122 209  70 122 235  86  71 100\n",
            "  71  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n",
            "\n",
            "-------------------------------------------------------------------------\n",
            "\n",
            "first parsed and normalized sentence for testing\n",
            "\n",
            " [12346  4109  5735 16617  9799  5167  8366  1666  6782  4757  1114   515\n",
            "  9799 14063  1114  9799  8134 11401  5361  8560  8366 15569 18548  6163\n",
            " 18496 15897 12064 12239 22658 13043  9878 23539  4757  6782 16359   570\n",
            "  8955 10152 10898 19514 11478  4109 13758 22591     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "\n",
            "tags\n",
            "\n",
            " [229 257 207 242 240  45 178  92 175  29 164 207 240 207 164 240 232 176\n",
            "  18 185 178 175  69 195  70 122  22 240  39 242 207 240  29  81  90  92\n",
            " 101 185  25 146 229 257 207  44   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sWwZ3UuAuZJ3"
      },
      "source": [
        "## Tags to One-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pmckYX7tuZJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "84cb89c2-ec08-46cb-c6ed-a703de888d38"
      },
      "source": [
        "def to_categoricals(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)\n",
        "\n",
        "cat_train_tags_y = to_categoricals(train_tags_y, len(tag2index))\n",
        "cat_eval_tags_y  = to_categoricals(eval_tags_y, len(tag2index))\n",
        "cat_test_tags_y  = to_categoricals(test_tags_y, len(tag2index))\n",
        "\n",
        "print(\"\\nparsed and normalized tags for the first sentence\\n\\n\", train_tags_y[0], \"\\n\")\n",
        "print(\"one-hot vectors matrix for the first sentence tags\\n\\n\", cat_train_tags_y[0], \"\\n\")\n",
        "print(\"one-hot vector for the first sentence tag\\n\\n\", cat_train_tags_y[0][0], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "parsed and normalized tags for the first sentence\n",
            "\n",
            " [240 239  25 229 240 232 100 240 232 178  81 185  20 289 185 178  90  92\n",
            " 240  64  22 178  70  45  44   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0] \n",
            "\n",
            "one-hot vectors matrix for the first sentence tags\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] \n",
            "\n",
            "one-hot vector for the first sentence tag\n",
            "\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g3-1Dd9WuZKj"
      },
      "source": [
        "# <font color='green'>Training</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jyfgUOkuZKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f1a322ba-12e7-40db-e5ba-18172c11f8f8"
      },
      "source": [
        "## Funcion que permite forzar el uso de GPU cuando estan presentes\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELLI2jA5uZKy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ff0b9a62-cb0a-48dc-b9da-ba0f48e552ff"
      },
      "source": [
        "input = Input(shape=(MAX_LENGTH,))\n",
        "word_embedding_size = 300\n",
        "\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=len(word2index), output_dim=word_embedding_size, input_length=MAX_LENGTH)(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
        "\n",
        "model = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "model = TimeDistributed(Dense(len(tag2index), activation=\"relu\"))(model)  \n",
        "\n",
        "# CRF Layer\n",
        "crf = CRF(len(tag2index))\n",
        "\n",
        "out = crf(model)  # output\n",
        "model = Model(input, out)\n",
        "\n",
        "\n",
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "print(\"\\n\")\n",
        "model.summary()\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 149)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 149, 300)          7349700   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 149, 600)          1442400   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 149, 600)          2882400   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 149, 291)          174891    \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 149, 291)          170235    \n",
            "=================================================================\n",
            "Total params: 12,019,626\n",
            "Trainable params: 12,019,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA8LGHabMK9c",
        "colab_type": "text"
      },
      "source": [
        "### <font color='orange'>[!] If using low-end GPU, COMMENT this block</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fG1ufNkwuZK4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "fbc73da4-ea65-4d49-ee83-647264604b2d"
      },
      "source": [
        "model_hist = model.fit(train_sentences_X, cat_train_tags_y,\n",
        "                       validation_data=(eval_sentences_X, cat_eval_tags_y),\n",
        "                       batch_size=64, \n",
        "                       epochs=25,\n",
        "                       validation_split=0.1,\n",
        "                       verbose=1)\n",
        "\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"mb-full.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"mb-full.h5\")\n",
        "print(\"Model saved to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3618 samples, validate on 1206 samples\n",
            "Epoch 1/25\n",
            "3618/3618 [==============================] - 71s 19ms/step - loss: 1.4285 - crf_viterbi_accuracy: 0.7854 - accuracy: 0.7850 - val_loss: 0.8534 - val_crf_viterbi_accuracy: 0.8140 - val_accuracy: 0.8141\n",
            "Epoch 2/25\n",
            "3618/3618 [==============================] - 66s 18ms/step - loss: 0.8286 - crf_viterbi_accuracy: 0.8156 - accuracy: 0.7850 - val_loss: 0.8094 - val_crf_viterbi_accuracy: 0.8171 - val_accuracy: 0.8172\n",
            "Epoch 3/25\n",
            "3618/3618 [==============================] - 66s 18ms/step - loss: 0.8017 - crf_viterbi_accuracy: 0.8178 - accuracy: 0.7850 - val_loss: 0.7924 - val_crf_viterbi_accuracy: 0.8188 - val_accuracy: 0.8189\n",
            "Epoch 4/25\n",
            "3618/3618 [==============================] - 66s 18ms/step - loss: 0.7835 - crf_viterbi_accuracy: 0.8196 - accuracy: 0.7850 - val_loss: 0.7677 - val_crf_viterbi_accuracy: 0.8236 - val_accuracy: 0.8237\n",
            "Epoch 5/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.7370 - crf_viterbi_accuracy: 0.8305 - accuracy: 0.7850 - val_loss: 0.6672 - val_crf_viterbi_accuracy: 0.8486 - val_accuracy: 0.8487\n",
            "Epoch 6/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.5893 - crf_viterbi_accuracy: 0.8646 - accuracy: 0.7850 - val_loss: 0.4825 - val_crf_viterbi_accuracy: 0.8915 - val_accuracy: 0.8915\n",
            "Epoch 7/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.4072 - crf_viterbi_accuracy: 0.9044 - accuracy: 0.7850 - val_loss: 0.3012 - val_crf_viterbi_accuracy: 0.9305 - val_accuracy: 0.9305\n",
            "Epoch 8/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.2596 - crf_viterbi_accuracy: 0.9362 - accuracy: 0.7850 - val_loss: 0.2120 - val_crf_viterbi_accuracy: 0.9487 - val_accuracy: 0.9487\n",
            "Epoch 9/25\n",
            "3618/3618 [==============================] - 66s 18ms/step - loss: 0.1768 - crf_viterbi_accuracy: 0.9557 - accuracy: 0.7850 - val_loss: 0.1687 - val_crf_viterbi_accuracy: 0.9607 - val_accuracy: 0.9607\n",
            "Epoch 10/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.1262 - crf_viterbi_accuracy: 0.9685 - accuracy: 0.7850 - val_loss: 0.1487 - val_crf_viterbi_accuracy: 0.9671 - val_accuracy: 0.9671\n",
            "Epoch 11/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0952 - crf_viterbi_accuracy: 0.9764 - accuracy: 0.7850 - val_loss: 0.1443 - val_crf_viterbi_accuracy: 0.9696 - val_accuracy: 0.9696\n",
            "Epoch 12/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0756 - crf_viterbi_accuracy: 0.9816 - accuracy: 0.7850 - val_loss: 0.1462 - val_crf_viterbi_accuracy: 0.9715 - val_accuracy: 0.9715\n",
            "Epoch 13/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0634 - crf_viterbi_accuracy: 0.9846 - accuracy: 0.7850 - val_loss: 0.1462 - val_crf_viterbi_accuracy: 0.9724 - val_accuracy: 0.9724\n",
            "Epoch 14/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0555 - crf_viterbi_accuracy: 0.9865 - accuracy: 0.7850 - val_loss: 0.1496 - val_crf_viterbi_accuracy: 0.9728 - val_accuracy: 0.9728\n",
            "Epoch 15/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0491 - crf_viterbi_accuracy: 0.9881 - accuracy: 0.7850 - val_loss: 0.1529 - val_crf_viterbi_accuracy: 0.9735 - val_accuracy: 0.9735\n",
            "Epoch 16/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0445 - crf_viterbi_accuracy: 0.9890 - accuracy: 0.7850 - val_loss: 0.1558 - val_crf_viterbi_accuracy: 0.9740 - val_accuracy: 0.9740\n",
            "Epoch 17/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0407 - crf_viterbi_accuracy: 0.9900 - accuracy: 0.7850 - val_loss: 0.1641 - val_crf_viterbi_accuracy: 0.9742 - val_accuracy: 0.9742\n",
            "Epoch 18/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0392 - crf_viterbi_accuracy: 0.9901 - accuracy: 0.7850 - val_loss: 0.1618 - val_crf_viterbi_accuracy: 0.9743 - val_accuracy: 0.9743\n",
            "Epoch 19/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0356 - crf_viterbi_accuracy: 0.9908 - accuracy: 0.7850 - val_loss: 0.1680 - val_crf_viterbi_accuracy: 0.9744 - val_accuracy: 0.9744\n",
            "Epoch 20/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0332 - crf_viterbi_accuracy: 0.9915 - accuracy: 0.7850 - val_loss: 0.1692 - val_crf_viterbi_accuracy: 0.9746 - val_accuracy: 0.9746\n",
            "Epoch 21/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0320 - crf_viterbi_accuracy: 0.9916 - accuracy: 0.7850 - val_loss: 0.1752 - val_crf_viterbi_accuracy: 0.9746 - val_accuracy: 0.9746\n",
            "Epoch 22/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0304 - crf_viterbi_accuracy: 0.9920 - accuracy: 0.7850 - val_loss: 0.1738 - val_crf_viterbi_accuracy: 0.9746 - val_accuracy: 0.9746\n",
            "Epoch 23/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0283 - crf_viterbi_accuracy: 0.9927 - accuracy: 0.7850 - val_loss: 0.1734 - val_crf_viterbi_accuracy: 0.9749 - val_accuracy: 0.9749\n",
            "Epoch 24/25\n",
            "3618/3618 [==============================] - 64s 18ms/step - loss: 0.0272 - crf_viterbi_accuracy: 0.9928 - accuracy: 0.7850 - val_loss: 0.1746 - val_crf_viterbi_accuracy: 0.9750 - val_accuracy: 0.9750\n",
            "Epoch 25/25\n",
            "3618/3618 [==============================] - 65s 18ms/step - loss: 0.0262 - crf_viterbi_accuracy: 0.9930 - accuracy: 0.7850 - val_loss: 0.1743 - val_crf_viterbi_accuracy: 0.9757 - val_accuracy: 0.9757\n",
            "Model saved to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E34QoI9MK9j",
        "colab_type": "text"
      },
      "source": [
        "### <font color='orange'>[!]  If using low-end GPU, UNCOMMENT this block</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkQiTEWxMK9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(\"mb-full.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VCfeub5auZK8"
      },
      "source": [
        "# <font color='green'>Evaluating</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GFzKxQtYuZK_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f7accfc-10c9-487c-c0ef-898e8b6636f1"
      },
      "source": [
        "scores = model.evaluate(test_sentences_X, cat_test_tags_y)\n",
        "print(scores[1] * 100)   # acc: 97.66269326210022"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206/1206 [==============================] - 8s 7ms/step\n",
            "97.698575258255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpBl7B2XMK90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fff6ef5f-163e-4b65-85b3-a52c5eaee1a7"
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "X_te = test_sentences_X[:201*128]\n",
        "test_pred = model.predict(np.array(X_te), verbose=1)\n",
        "#4768/4768 [==============================] - 64s 13ms/step\n",
        "idx2tag = {i: w for w, i in tag2index.items()}\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = test2label(test_tags_y[:201*128])\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "print(classification_report(test_labels, pred_labels))\n",
        "#print(X_te[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206/1206 [==============================] - 5s 4ms/step\n",
            "F1-score: 89.2%\n",
            "           precision    recall  f1-score   support\n",
            "\n",
            "    sps00       0.99      0.99      0.99      4995\n",
            "       Fc       1.00      1.00      1.00      2225\n",
            "       cc       0.98      1.00      0.99      1146\n",
            "  vmip3s0       0.97      0.88      0.93       624\n",
            "  vmg0000       0.16      0.58      0.25       105\n",
            "  ncfp000       0.96      0.83      0.89       742\n",
            "   da0ms0       1.00      1.00      1.00      1203\n",
            "    spcms       1.00      0.99      0.99       684\n",
            "   aq0cp0       0.91      0.75      0.82       247\n",
            " p0000000       0.71      0.49      0.58       184\n",
            "       cs       0.93      0.90      0.91       878\n",
            "  np00000       0.17      0.13      0.15        67\n",
            "  ncmp000       0.92      0.87      0.89      1139\n",
            "  ncms000       0.82      0.90      0.86      2259\n",
            "       rg       0.97      0.89      0.93      1067\n",
            "   aq0mpp       0.62      0.51      0.56        99\n",
            "   ao0ms0       0.98      0.93      0.96        69\n",
            "                1.00      1.00      1.00      1206\n",
            "  vmn0000       0.99      0.74      0.85       801\n",
            "   da0fs0       0.99      1.00      1.00      1348\n",
            " pp3mp000       1.00      0.90      0.95        21\n",
            "  ncfs000       0.91      0.91      0.91      2156\n",
            "  vmip3p0       1.00      0.74      0.85       283\n",
            "  nc00000       0.14      0.11      0.12        38\n",
            "  vmip1p0       1.00      0.75      0.86        53\n",
            "   aq0msp       0.92      0.68      0.78       174\n",
            "   aq0cs0       0.95      0.81      0.88       616\n",
            " pi0mp000       1.00      0.37      0.54        38\n",
            "   da0mp0       1.00      1.00      1.00       628\n",
            "       Fe       1.00      1.00      1.00       605\n",
            "  vmp00sm       0.93      0.87      0.90       285\n",
            "  np0000p       0.97      0.47      0.64       716\n",
            "  vaip3s0       1.00      1.00      1.00       172\n",
            "      SUJ       1.00      1.00      1.00       747\n",
            "        W       0.92      0.61      0.73       183\n",
            " pr0cn000       0.89      0.94      0.92       576\n",
            "   da0fp0       0.99      1.00      0.99       382\n",
            "   dd0ms0       0.97      1.00      0.99       104\n",
            "       rn       0.98      1.00      0.99       236\n",
            " px3mp000       0.00      0.00      0.00         1\n",
            "   aq0fsp       0.93      0.48      0.64       114\n",
            "  vmif3s0       1.00      0.68      0.81        97\n",
            "  np0000o       0.31      0.68      0.42       676\n",
            "  vmp00sf       0.83      0.36      0.50        14\n",
            "       Fp       1.00      1.00      1.00      1169\n",
            "  np0000a       0.41      0.41      0.41       175\n",
            "   dp3cs0       1.00      1.00      1.00       266\n",
            "   aq0fs0       0.90      0.69      0.78       386\n",
            "  np0000l       0.53      0.73      0.62       398\n",
            "   dn0cp0       0.88      0.96      0.92       156\n",
            "        Z       0.97      0.64      0.77       261\n",
            "   di0fs0       0.91      0.99      0.95       322\n",
            "   dp3cp0       1.00      1.00      1.00       100\n",
            "  vsip3s0       1.00      1.00      1.00       194\n",
            " pp3fsa00       1.00      0.20      0.33        15\n",
            " pp1cp000       0.85      0.93      0.89        30\n",
            "       Fg       1.00      1.00      1.00       231\n",
            "  vmii3p0       1.00      0.39      0.56        61\n",
            "  vmsp3s0       0.09      0.80      0.16        70\n",
            " pi0fp000       1.00      0.60      0.75         5\n",
            " pi0ms000       0.91      0.57      0.70        54\n",
            "  vaip3p0       1.00      1.00      1.00        51\n",
            "  vmii3s0       0.94      0.72      0.82       129\n",
            " pp1mp000       1.00      1.00      1.00        12\n",
            "  vmsi3s0       0.73      0.31      0.43        26\n",
            "   di0ms0       0.94      0.99      0.96       415\n",
            "  ncmn000       1.00      0.50      0.67        24\n",
            "  nccn000       0.50      0.33      0.40         3\n",
            " pn0cp000       0.88      0.52      0.65        27\n",
            "  vmsi3p0       0.00      0.00      0.00        16\n",
            "  nccs000       0.91      0.76      0.83       138\n",
            "      Fpt       0.99      1.00      1.00       143\n",
            "   di0cp0       0.80      0.50      0.62         8\n",
            " pr0cs000       0.97      1.00      0.98        30\n",
            " p0300000       0.62      0.81      0.70       200\n",
            "   aq0ms0       0.88      0.72      0.79       488\n",
            "  vmip1s0       0.73      0.69      0.71        52\n",
            "       Zp       1.00      0.46      0.63        35\n",
            "  vsis3p0       1.00      1.00      1.00         9\n",
            "  vmic3s0       0.80      0.52      0.63        23\n",
            "  vaii3s0       0.95      1.00      0.97        35\n",
            "   aq0fp0       0.93      0.62      0.75       160\n",
            "   aq0mp0       0.89      0.61      0.72       166\n",
            "  vmis3p0       0.99      0.61      0.75       118\n",
            "  vmis3s0       0.99      0.84      0.91       612\n",
            " pr000000       0.96      0.80      0.87        30\n",
            "  nccp000       0.92      0.64      0.76       104\n",
            "      Fpa       0.99      1.00      0.99       144\n",
            "  vsp00sm       0.96      1.00      0.98        25\n",
            "   di0mp0       0.79      0.98      0.87        95\n",
            " pp3ms000       0.95      1.00      0.98        20\n",
            " pd0fs000       1.00      0.62      0.77         8\n",
            "       Fd       0.98      1.00      0.99        81\n",
            " pp3msa00       0.72      0.97      0.82        34\n",
            " pp1csn00       1.00      0.92      0.96        13\n",
            " pt0cs000       0.89      0.89      0.89        19\n",
            "   dd0fs0       0.95      1.00      0.98        63\n",
            "   ao0fp0       1.00      1.00      1.00         6\n",
            "   dt0cn0       0.67      0.80      0.73         5\n",
            " pp3ns000       1.00      0.92      0.96        12\n",
            "   di0fp0       0.96      0.98      0.97        54\n",
            "   ao0fs0       0.93      0.98      0.96        56\n",
            "   da0ns0       0.99      0.91      0.94        85\n",
            " pi0cs000       0.95      0.98      0.96        53\n",
            "  vmic1p0       0.14      0.50      0.22         2\n",
            "  vsip3p0       1.00      1.00      1.00        41\n",
            "   aq0fpp       0.23      0.60      0.34        62\n",
            "  vmm03p0       0.00      0.00      0.00         6\n",
            "  vmii1p0       0.00      0.00      0.00         5\n",
            " pp3csd00       0.86      1.00      0.92        42\n",
            "  vmsp3p0       0.82      0.42      0.55        43\n",
            "       Zm       0.91      0.97      0.94        30\n",
            " pi0fs000       0.00      0.00      0.00        20\n",
            "  vaii1s0       0.00      0.00      0.00         1\n",
            "  vsip1s0       1.00      0.50      0.67         2\n",
            " pr0cp000       0.88      0.88      0.88         8\n",
            " pn0mp000       0.00      0.00      0.00         6\n",
            "   dd0mp0       0.89      1.00      0.94        34\n",
            " pd0fp000       1.00      0.50      0.67         4\n",
            "  vsis3s0       0.95      1.00      0.97        39\n",
            "   di0cs0       1.00      1.00      1.00        32\n",
            "  vmsp1s0       0.00      0.00      0.00         6\n",
            "  vmif3p0       0.85      0.66      0.74        35\n",
            " pp3fs000       0.91      1.00      0.95        10\n",
            "   dp1msp       1.00      1.00      1.00         6\n",
            "      Fit       1.00      1.00      1.00        27\n",
            "  vsn0000       0.98      0.98      0.98        47\n",
            "  vsii3s0       0.93      1.00      0.96        26\n",
            " pd0ns000       0.97      1.00      0.98        30\n",
            "  vmis1p0       1.00      0.25      0.40         4\n",
            "   dp3ms0       0.00      0.00      0.00         1\n",
            "  vasi3p0       1.00      1.00      1.00         1\n",
            " pp2cs000       0.88      0.88      0.88         8\n",
            "   dd0fp0       0.94      1.00      0.97        17\n",
            "  vasp3s0       0.88      1.00      0.93         7\n",
            " pp3cn000       0.00      0.00      0.00         8\n",
            "     sn.e       0.00      0.00      0.00         2\n",
            " pd0mp000       1.00      0.25      0.40         4\n",
            " pp3cpd00       0.86      1.00      0.93        19\n",
            "  vaii3p0       0.86      1.00      0.92         6\n",
            "       Fx       0.96      1.00      0.98        23\n",
            "  vssp3s0       0.93      1.00      0.97        14\n",
            "      Fat       1.00      0.89      0.94         9\n",
            "       Fs       1.00      0.91      0.95        11\n",
            "  vasi3s0       1.00      1.00      1.00         8\n",
            " pr0fs000       1.00      1.00      1.00         6\n",
            "  vmic3p0       0.75      0.60      0.67         5\n",
            "  vais3s0       1.00      1.00      1.00         5\n",
            " pt000000       1.00      1.00      1.00        12\n",
            "  vsif3p0       0.25      0.33      0.29         3\n",
            "  van0000       1.00      1.00      1.00        15\n",
            "   ao0mp0       0.92      1.00      0.96        23\n",
            "      Faa       1.00      1.00      1.00         7\n",
            "   dp1css       1.00      1.00      1.00         8\n",
            "  vmif1p0       0.25      0.33      0.29         6\n",
            " pp1cs000       0.89      0.94      0.92        18\n",
            "  vmp00pm       0.15      0.15      0.15        13\n",
            "  vmii2s0       0.00      0.00      0.00         1\n",
            "  vmm02s0       0.00      0.00      0.00         7\n",
            "   dn0mp0       0.60      0.90      0.72        10\n",
            " pp3fp000       1.00      1.00      1.00         8\n",
            "   dp1fpp       1.00      1.00      1.00         4\n",
            "   dn0fs0       0.00      0.00      0.00         7\n",
            "  vaip1p0       0.91      1.00      0.95        10\n",
            "  vmp00pf       0.00      0.00      0.00         7\n",
            "  vmic1s0       0.00      0.00      0.00         4\n",
            "  vaic3s0       1.00      1.00      1.00         4\n",
            "  ncfn000       1.00      0.87      0.93        15\n",
            "      Fia       1.00      1.00      1.00         7\n",
            " pp3cno00       1.00      1.00      1.00         2\n",
            " pp3cpa00       0.00      0.00      0.00         3\n",
            "  vssi3p0       0.00      0.00      0.00         1\n",
            "   aq0cn0       0.20      0.20      0.20        10\n",
            "  vasp3p0       0.00      0.00      0.00         4\n",
            "  vmii1s0       0.00      0.00      0.00         3\n",
            "  vmif1s0       0.00      0.00      0.00         2\n",
            " pd0ms000       1.00      0.71      0.83        14\n",
            "  vmsp1p0       1.00      0.25      0.40         4\n",
            "  vsif1s0       0.00      0.00      0.00         1\n",
            " pp3fpa00       1.00      0.56      0.71         9\n",
            " pp2cp00p       0.00      0.00      0.00         2\n",
            "  vsif3s0       1.00      1.00      1.00        16\n",
            " pp3csa00       0.00      0.00      0.00         7\n",
            "  vaic3p0       0.00      0.00      0.00         3\n",
            "  vaii1p0       0.00      0.00      0.00         1\n",
            "  vsic3s0       1.00      1.00      1.00         8\n",
            " pn0ms000       0.00      0.00      0.00         2\n",
            " pr0fp000       1.00      1.00      1.00         1\n",
            "   dd0cp0       1.00      0.50      0.67         2\n",
            "   dn0ms0       1.00      0.20      0.33         5\n",
            "  vmm03s0       0.50      0.11      0.18         9\n",
            " p010p000       0.33      0.17      0.22         6\n",
            " pp3mpa00       1.00      0.50      0.67         4\n",
            "  vsii3p0       1.00      1.00      1.00         4\n",
            "   dp1mpp       1.00      1.00      1.00         3\n",
            "  vmis1s0       1.00      0.67      0.80         3\n",
            " pr0ms000       1.00      1.00      1.00         7\n",
            "   dp1fsp       1.00      0.88      0.93         8\n",
            "   dd0cs0       1.00      0.50      0.67         4\n",
            "  vsg0000       1.00      1.00      1.00         9\n",
            " pn0fp000       0.00      0.00      0.00         1\n",
            "   dn0fp0       1.00      0.50      0.67         2\n",
            "   de0cn0       0.00      0.00      0.00         1\n",
            " pp3cna00       0.00      0.00      0.00         5\n",
            " pp1cso00       0.75      1.00      0.86         3\n",
            "  vap00sm       1.00      1.00      1.00         3\n",
            " px3ns000       0.00      0.00      0.00         1\n",
            "  vmii2p0       0.00      0.00      0.00         1\n",
            "  vaif3s0       1.00      1.00      1.00         3\n",
            "  vmis2s0       0.00      0.00      0.00         4\n",
            " pn0fs000       0.00      0.00      0.00         2\n",
            "   dp1cps       1.00      0.75      0.86         4\n",
            "  vssp3p0       1.00      0.50      0.67         2\n",
            "  vmip2s0       0.33      0.40      0.36         5\n",
            "   dn0cs0       0.00      0.00      0.00         1\n",
            " pp2csn00       0.00      0.00      0.00         1\n",
            "  vmif2s0       0.00      0.00      0.00         1\n",
            "  aq00000       0.00      0.00      0.00         2\n",
            "  vam02s0       0.00      0.00      0.00         1\n",
            "  vaip1s0       0.86      1.00      0.92         6\n",
            "  vsic3p0       1.00      1.00      1.00         2\n",
            "       Fz       0.00      0.00      0.00         3\n",
            " p010s000       0.00      0.00      0.00         2\n",
            " pi0cp000       0.50      1.00      0.67         3\n",
            "  vaip2p0       0.00      0.00      0.00         1\n",
            "  vmsi1s0       0.00      0.00      0.00         3\n",
            "        i       0.00      0.00      0.00         3\n",
            "  vaic1p0       0.00      0.00      0.00         1\n",
            "  vam03s0       0.00      0.00      0.00         1\n",
            "  vsii1p0       0.00      0.00      0.00         1\n",
            " px3fs000       0.00      0.00      0.00         1\n",
            " pp2cs00p       1.00      1.00      1.00         4\n",
            " pr0mp000       1.00      0.67      0.80         3\n",
            "  vsip2s0       1.00      1.00      1.00         1\n",
            " pp2cso00       0.00      0.00      0.00         1\n",
            " px3ms000       0.00      0.00      0.00         1\n",
            " p020s000       0.00      0.00      0.00         1\n",
            "  vsii1s0       0.00      0.00      0.00         1\n",
            "\n",
            "micro avg       0.89      0.89      0.89     38873\n",
            "macro avg       0.93      0.89      0.90     38873\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Qbe0SmiuZLG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "84876b23-14f2-48dc-807d-9934a52571dd"
      },
      "source": [
        "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
        "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
        "    blue= '#34495E'\n",
        "    green = '#2ECC71'\n",
        "    orange = '#E23B13'\n",
        "    \n",
        "    # plot model loss\n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
        "    ax1.plot(range(1, len(train_loss) + 1), train_loss, blue, linewidth=5, label='training')\n",
        "    ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, green, linewidth=5, label='validation')\n",
        "    ax1.set_xlabel('# epoch')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.tick_params('y')\n",
        "    ax1.legend(loc='upper right', shadow=False)\n",
        "    ax1.set_title('Model loss through #epochs', color=orange, fontweight='bold')\n",
        "    \n",
        "    # plot model accuracy\n",
        "    ax2.plot(range(1, len(train_acc) + 1), train_acc, blue, linewidth=5, label='training')\n",
        "    ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, green, linewidth=5, label='validation')\n",
        "    ax2.set_xlabel('# epoch')\n",
        "    ax2.set_ylabel('accuracy')\n",
        "    ax2.tick_params('y')\n",
        "    ax2.legend(loc='lower right', shadow=False)\n",
        "    ax2.set_title('Model accuracy through #epochs', color=orange, fontweight='bold')\n",
        "    \n",
        "plot_model_performance(\n",
        "    train_loss=model_hist.history.get('loss', []),\n",
        "    train_acc=model_hist.history.get('crf_viterbi_accuracy', []),\n",
        "    train_val_loss=model_hist.history.get('val_loss', []),\n",
        "    train_val_acc=model_hist.history.get('val_crf_viterbi_accuracy', [])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1yWdiaCduZLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9908df7a-6803-4a4b-bd6b-39d6e2100d38"
      },
      "source": [
        "# función que recibe en sequences la lista de oraciones donde cada elemento de la oracion es un one-hot vector\n",
        "# permite convertir Indices en Tags\n",
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences\n",
        "\n",
        "# Prediccion sobre el conjunto de pruebas. De la distribución probabilística a etiquetas\n",
        "prediction = model.predict(test_sentences_X)\n",
        "log_tokens = logits_to_tokens(prediction, {i: t for t, i in tag2index.items()})\n",
        "\n",
        "print(\"\\ntags predicted for evaluating:\\n\\n\", log_tokens[0], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tags predicted for evaluating:\n",
            "\n",
            " ['ncfp000', 'spcms', 'ncms000', 'aq0ms0', 'sps00', 'np0000o', 'Fc', 'vmip3p0', 'cs', 'da0ms0', 'Fe', 'ncms000', 'sps00', 'ncms000', 'Fe', 'sps00', 'np0000p', 'vaip3s0', 'vmp00sm', 'np0000o', 'Fc', 'cs', 'sn.e-SUJ', 'vmsp3s0', 'da0fs0', 'ncfs000', 'aq0fs0', 'sps00', 'di0ms0', 'aq0ms0', 'ncms000', 'sps00', 'da0ms0', 'pr0cn000', 'p0000000', 'vmip3p0', 'vmn0000', 'rg', 'da0fp0', 'di0fp0', 'ncfp000', 'spcms', 'ncms000', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSE-XrafuZLa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab728d29-55c0-42bb-e19c-488fc8b1a739"
      },
      "source": [
        "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
        "k = 0\n",
        "for i, lista_etiquetas_oracion in enumerate(test_tags):\n",
        "    for j, etiquetas in enumerate(lista_etiquetas_oracion):\n",
        "        k = k + 1\n",
        "        results.loc[k, 'Expected'] = etiquetas\n",
        "        results.loc[k, 'Predicted'] = log_tokens[i][j]\n",
        "\n",
        "print(\"\\nresults:\\n\\n\", results)\n",
        "print('\\n\\nclassification_report:\\n\\n', classification_report(results['Expected'], results['Predicted']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "results:\n",
            "\n",
            "       Expected Predicted\n",
            "1      ncfp000   ncfp000\n",
            "2        spcms     spcms\n",
            "3      ncms000   ncms000\n",
            "4       aq0ms0    aq0ms0\n",
            "5        sps00     sps00\n",
            "...        ...       ...\n",
            "37840  np0000l   np0000o\n",
            "37841       Fc        Fc\n",
            "37842    sps00     sps00\n",
            "37843  np0000l   np0000l\n",
            "37844       Fp        Fp\n",
            "\n",
            "[37844 rows x 2 columns]\n",
            "\n",
            "\n",
            "classification_report:\n",
            "\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "  dp3cs0O       1.00      1.00      1.00       266\n",
            "      FsO       1.00      0.91      0.95        11\n",
            " ncms000O       0.82      0.90      0.86      2259\n",
            "      csO       0.93      0.90      0.91       878\n",
            "      rgO       0.97      0.89      0.93      1067\n",
            " vsn0000O       0.98      0.98      0.98        47\n",
            "  da0ms0O       1.00      1.00      1.00      1203\n",
            "      FcO       1.00      1.00      1.00      2225\n",
            "  dd0fs0O       0.95      1.00      0.98        63\n",
            "p0300000O       0.62      0.81      0.70       200\n",
            " vmn0000O       0.99      0.74      0.85       801\n",
            "  aq0cs0O       0.95      0.81      0.88       616\n",
            " ncfs000O       0.91      0.91      0.91      2156\n",
            "  dn0cp0O       0.88      0.96      0.92       156\n",
            "     SUJO       1.00      1.00      1.00       747\n",
            " vmip3p0O       1.00      0.74      0.85       283\n",
            "   sps00O       0.99      0.99      0.99      4995\n",
            "   spcmsO       1.00      0.99      0.99       684\n",
            " ncmp000O       0.92      0.87      0.89      1139\n",
            "pr0cs000O       0.97      1.00      0.98        30\n",
            " vmip3s0O       0.97      0.88      0.93       624\n",
            "pp3mp000O       1.00      0.90      0.95        21\n",
            "  da0fs0O       0.99      1.00      1.00      1348\n",
            "      FpO       1.00      1.00      1.00      1164\n",
            "      ccO       0.98      1.00      0.99      1146\n",
            " np0000pO       0.97      0.47      0.64       716\n",
            "  di0ms0O       0.94      0.99      0.96       415\n",
            "  aq0fs0O       0.90      0.69      0.78       386\n",
            " np0000oO       0.31      0.68      0.42       676\n",
            " vmp00smO       0.93      0.87      0.90       285\n",
            " np0000aO       0.41      0.41      0.41       175\n",
            " vssp3s0O       0.93      1.00      0.97        14\n",
            "pt0cs000O       0.89      0.89      0.89        19\n",
            "pd0ns000O       0.97      1.00      0.98        30\n",
            "pr0cn000O       0.89      0.94      0.92       576\n",
            " vmsp3p0O       0.82      0.42      0.55        43\n",
            "pr000000O       0.96      0.80      0.87        30\n",
            "  aq0cp0O       0.91      0.75      0.82       247\n",
            "  da0fp0O       0.99      1.00      0.99       382\n",
            "     FpaO       0.99      1.00      0.99       144\n",
            "      FgO       1.00      1.00      1.00       231\n",
            " vaii3p0O       0.86      1.00      0.92         6\n",
            "  da0mp0O       1.00      1.00      1.00       628\n",
            "pp1mp000O       1.00      1.00      1.00        12\n",
            "  di0fs0O       0.91      0.99      0.95       322\n",
            " vmis3p0O       0.99      0.61      0.75       118\n",
            "     FitO       1.00      1.00      1.00        27\n",
            " vmif3s0O       1.00      0.68      0.81        97\n",
            "  aq0fp0O       0.93      0.62      0.75       160\n",
            " vmsp3s0O       0.09      0.80      0.16        70\n",
            " vaip3s0O       1.00      1.00      1.00       172\n",
            "       ZO       0.97      0.64      0.77       261\n",
            " vmif1s0O       0.00      0.00      0.00         2\n",
            " vsip3s0O       1.00      1.00      1.00       194\n",
            " vmis3s0O       0.99      0.84      0.91       612\n",
            " ncfp000O       0.96      0.83      0.89       742\n",
            " vaip1p0O       0.91      1.00      0.95        10\n",
            " vmii3p0O       1.00      0.39      0.56        61\n",
            " np0000lO       0.53      0.73      0.62       398\n",
            "  aq0mp0O       0.89      0.61      0.72       166\n",
            " nccs000O       0.91      0.76      0.83       138\n",
            "     FptO       0.99      1.00      1.00       143\n",
            " vmic3s0O       0.80      0.52      0.63        23\n",
            " vaii3s0O       0.95      1.00      0.97        35\n",
            "pp3csd00O       0.86      1.00      0.92        42\n",
            "  di0mp0O       0.79      0.98      0.87        95\n",
            "       WO       0.92      0.61      0.73       183\n",
            "pi0fs000O       0.00      0.00      0.00        20\n",
            "  di0fp0O       0.96      0.98      0.97        54\n",
            "p0000000O       0.71      0.49      0.58       184\n",
            "      rnO       0.98      1.00      0.99       236\n",
            "pp1cp000O       0.85      0.93      0.89        30\n",
            " vmip1s0O       0.73      0.69      0.71        52\n",
            "      FeO       1.00      1.00      1.00       605\n",
            "  da0ns0O       0.99      0.91      0.94        85\n",
            "  dp3cp0O       1.00      1.00      1.00       100\n",
            "      FdO       0.98      1.00      0.99        81\n",
            "  aq0mspO       0.92      0.68      0.78       174\n",
            " vsis3p0O       1.00      1.00      1.00         9\n",
            " np00000O       0.17      0.13      0.15        67\n",
            "  aq0ms0O       0.88      0.72      0.79       488\n",
            " vmg0000O       0.16      0.58      0.25       105\n",
            "pp3cn000O       0.00      0.00      0.00         8\n",
            "  ao0ms0O       0.98      0.93      0.96        69\n",
            "pi0ms000O       0.91      0.57      0.70        54\n",
            "  aq0fspO       0.93      0.48      0.64       114\n",
            " vsip3p0O       1.00      1.00      1.00        41\n",
            "      ZpO       1.00      0.46      0.63        35\n",
            "pi0mp000O       1.00      0.37      0.54        38\n",
            "  dd0mp0O       0.89      1.00      0.94        34\n",
            " vsis3s0O       0.95      1.00      0.97        39\n",
            "pt000000O       1.00      1.00      1.00        12\n",
            " vmp00pfO       0.00      0.00      0.00         7\n",
            "  dd0cs0O       1.00      0.50      0.67         4\n",
            "  di0cp0O       0.80      0.50      0.62         8\n",
            " vasp3p0O       0.00      0.00      0.00         4\n",
            "pd0fs000O       1.00      0.62      0.77         8\n",
            " nccp000O       0.92      0.64      0.76       104\n",
            "pp1cs000O       0.89      0.94      0.92        18\n",
            "  dd0ms0O       0.97      1.00      0.99       104\n",
            " vmsi3p0O       0.00      0.00      0.00        16\n",
            "  ao0fs0O       0.93      0.98      0.96        56\n",
            "pi0cs000O       0.95      0.98      0.96        53\n",
            "  aq0mppO       0.62      0.51      0.56        99\n",
            " vmii3s0O       0.94      0.72      0.82       129\n",
            " vmm02s0O       0.00      0.00      0.00         7\n",
            " vaip3p0O       1.00      1.00      1.00        51\n",
            " vsic3s0O       1.00      1.00      1.00         8\n",
            "  dn0mp0O       0.60      0.90      0.72        10\n",
            "pn0cp000O       0.88      0.52      0.65        27\n",
            "  dp1cssO       1.00      1.00      1.00         8\n",
            " vsii3p0O       1.00      1.00      1.00         4\n",
            "pd0ms000O       1.00      0.71      0.83        14\n",
            " vmip1p0O       1.00      0.75      0.86        53\n",
            " vmsi3s0O       0.73      0.31      0.43        26\n",
            "  ao0mp0O       0.92      1.00      0.96        23\n",
            " vmic3p0O       0.75      0.60      0.67         5\n",
            " vsii3s0O       0.93      1.00      0.96        26\n",
            " vmii1p0O       0.00      0.00      0.00         5\n",
            "pn0ms000O       0.00      0.00      0.00         2\n",
            " nccn000O       0.50      0.33      0.40         3\n",
            " vmp00pmO       0.15      0.15      0.15        13\n",
            " nc00000O       0.14      0.11      0.12        38\n",
            "  di0cs0O       1.00      1.00      1.00        32\n",
            "pp3ns000O       1.00      0.92      0.96        12\n",
            " vsp00smO       0.96      1.00      0.98        25\n",
            "pp3msa00O       0.72      0.97      0.82        34\n",
            " vmsp1s0O       0.00      0.00      0.00         6\n",
            " ncmn000O       1.00      0.50      0.67        24\n",
            "pp3cpd00O       0.86      1.00      0.93        19\n",
            "p010p000O       0.33      0.17      0.22         6\n",
            " vasp3s0O       0.88      1.00      0.93         7\n",
            "pp3cna00O       0.00      0.00      0.00         5\n",
            "  ao0fp0O       1.00      1.00      1.00         6\n",
            " van0000O       1.00      1.00      1.00        15\n",
            "  dp1fspO       1.00      0.88      0.93         8\n",
            "  aq0fppO       0.23      0.60      0.34        62\n",
            "pp3fsa00O       1.00      0.20      0.33        15\n",
            "  dt0cn0O       0.67      0.80      0.73         5\n",
            " vmp00sfO       0.83      0.36      0.50        14\n",
            " vmip2s0O       0.33      0.40      0.36         5\n",
            " vmif2s0O       0.00      0.00      0.00         1\n",
            " vmif3p0O       0.85      0.66      0.74        35\n",
            " vmm03p0O       0.00      0.00      0.00         6\n",
            "  dd0fp0O       0.94      1.00      0.97        17\n",
            "    sn.eO       0.00      0.00      0.00         2\n",
            " vais3s0O       1.00      1.00      1.00         5\n",
            "     FatO       1.00      0.89      0.94         9\n",
            "pp1csn00O       1.00      0.92      0.96        13\n",
            " vmis2s0O       0.00      0.00      0.00         4\n",
            " vmis1p0O       1.00      0.25      0.40         4\n",
            "pd0fp000O       1.00      0.50      0.67         4\n",
            "pp3fs000O       0.91      1.00      0.95        10\n",
            "pp1cso00O       0.75      1.00      0.86         3\n",
            "pp3mpa00O       1.00      0.50      0.67         4\n",
            "      FxO       0.96      1.00      0.98        23\n",
            " vmm03s0O       0.50      0.11      0.18         9\n",
            "pp3csa00O       0.00      0.00      0.00         7\n",
            "      ZmO       0.91      0.97      0.94        30\n",
            " vasi3s0O       1.00      1.00      1.00         8\n",
            "pr0cp000O       0.88      0.88      0.88         8\n",
            "  dp1mspO       1.00      1.00      1.00         6\n",
            "     FiaO       1.00      1.00      1.00         7\n",
            "px3mp000O       0.00      0.00      0.00         1\n",
            "pp2cs000O       0.88      0.88      0.88         8\n",
            "pr0fs000O       1.00      1.00      1.00         6\n",
            "pr0fp000O       1.00      1.00      1.00         1\n",
            "  dn0ms0O       1.00      0.20      0.33         5\n",
            "pr0ms000O       1.00      1.00      1.00         7\n",
            " vsif3s0O       1.00      1.00      1.00        16\n",
            " ncfn000O       1.00      0.87      0.93        15\n",
            " vsg0000O       1.00      1.00      1.00         9\n",
            "     FaaO       1.00      1.00      1.00         7\n",
            "  dp1mppO       1.00      1.00      1.00         3\n",
            " vasi3p0O       1.00      1.00      1.00         1\n",
            "  dp1cpsO       1.00      0.75      0.86         4\n",
            "pn0mp000O       0.00      0.00      0.00         6\n",
            " vmic1s0O       0.00      0.00      0.00         4\n",
            " vaic1p0O       0.00      0.00      0.00         1\n",
            " vmis1s0O       1.00      0.67      0.80         3\n",
            "p020s000O       0.00      0.00      0.00         1\n",
            "  aq0cn0O       0.20      0.20      0.20        10\n",
            " vam03s0O       0.00      0.00      0.00         1\n",
            " vmsp1p0O       1.00      0.25      0.40         4\n",
            " vap00smO       1.00      1.00      1.00         3\n",
            "  dn0fs0O       0.00      0.00      0.00         7\n",
            "pp3ms000O       0.95      1.00      0.98        20\n",
            "pi0cp000O       0.50      1.00      0.67         3\n",
            " vsic3p0O       1.00      1.00      1.00         2\n",
            "pd0mp000O       1.00      0.25      0.40         4\n",
            " vaip2p0O       0.00      0.00      0.00         1\n",
            "pp3fp000O       1.00      1.00      1.00         8\n",
            "pp3cno00O       1.00      1.00      1.00         2\n",
            " vaic3s0O       1.00      1.00      1.00         4\n",
            " vam02s0O       0.00      0.00      0.00         1\n",
            " vaip1s0O       0.86      1.00      0.92         6\n",
            " vaic3p0O       0.00      0.00      0.00         3\n",
            "pp2cp00pO       0.00      0.00      0.00         2\n",
            "pp2csn00O       0.00      0.00      0.00         1\n",
            "pp3fpa00O       1.00      0.56      0.71         9\n",
            " vmii2s0O       0.00      0.00      0.00         1\n",
            " vmii1s0O       0.00      0.00      0.00         3\n",
            "px3ms000O       0.00      0.00      0.00         1\n",
            " vsip1s0O       1.00      0.50      0.67         2\n",
            "  dn0fp0O       1.00      0.50      0.67         2\n",
            "  dn0cs0O       0.00      0.00      0.00         1\n",
            "pi0fp000O       1.00      0.60      0.75         5\n",
            " vssp3p0O       1.00      0.50      0.67         2\n",
            "  dp1fppO       1.00      1.00      1.00         4\n",
            "  de0cn0O       0.00      0.00      0.00         1\n",
            " vsii1p0O       0.00      0.00      0.00         1\n",
            " vmif1p0O       0.25      0.33      0.29         6\n",
            " vsif3p0O       0.25      0.33      0.29         3\n",
            " vaii1s0O       0.00      0.00      0.00         1\n",
            "pr0mp000O       1.00      0.67      0.80         3\n",
            " vaif3s0O       1.00      1.00      1.00         3\n",
            "  dd0cp0O       1.00      0.50      0.67         2\n",
            " vmii2p0O       0.00      0.00      0.00         1\n",
            "      FzO       0.00      0.00      0.00         3\n",
            "pp2cs00pO       1.00      1.00      1.00         4\n",
            "px3ns000O       0.00      0.00      0.00         1\n",
            "pp2cso00O       0.00      0.00      0.00         1\n",
            " vsif1s0O       0.00      0.00      0.00         1\n",
            " vsip2s0O       1.00      1.00      1.00         1\n",
            " vmsi1s0O       0.00      0.00      0.00         3\n",
            " vssi3p0O       0.00      0.00      0.00         1\n",
            "pn0fs000O       0.00      0.00      0.00         2\n",
            "pn0fp000O       0.00      0.00      0.00         1\n",
            " vaii1p0O       0.00      0.00      0.00         1\n",
            "pp3cpa00O       0.00      0.00      0.00         3\n",
            "       iO       0.00      0.00      0.00         3\n",
            " aq00000O       0.00      0.00      0.00         2\n",
            "  dp3ms0O       0.00      0.00      0.00         1\n",
            "p010s000O       0.00      0.00      0.00         2\n",
            " vmic1p0O       0.14      0.50      0.22         2\n",
            "px3fs000O       0.00      0.00      0.00         1\n",
            " vsii1s0O       0.00      0.00      0.00         1\n",
            "\n",
            "micro avg       0.89      0.89      0.89     37662\n",
            "macro avg       0.92      0.89      0.90     37662\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LswNKDP6uZLf"
      },
      "source": [
        "# <font color='green'>Testing</font> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loMxp8OhMK-T",
        "colab_type": "text"
      },
      "source": [
        "### <font color='orange'>[!]  If running online, COMMENT this block (Graphic Interface)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZWoNvq1PuZLj",
        "colab": {}
      },
      "source": [
        "# def pos_tagging():\n",
        "# #    sentence=\"Correr es importante para mi .\"\n",
        "# #    sentence=\"El hombre bajo corre bajo el puente con bajo índice de adrenalina\"\n",
        "\n",
        "#     test_samples = [inputText.get(\"1.0\",END).split()]  \n",
        "#     test_samples_X = []\n",
        "#     for s in test_samples:\n",
        "#         s_int = []\n",
        "#         for w in s:\n",
        "#             try:\n",
        "#                 s_int.append(word2index[w.lower()])\n",
        "#             except KeyError:\n",
        "#                 s_int.append(word2index['-OOV-'])\n",
        "\n",
        "#         test_samples_X.append(s_int)\n",
        "\n",
        "#     test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "    \n",
        "#     predictions = model.predict(test_samples_X)\n",
        "#     tags = predictions.shape[2]\n",
        "\n",
        "#     heads = test_samples[0]\n",
        "#     body = [log_tokens[0][:len(test_samples[0])]]\n",
        "    \n",
        "#     index = 0  \n",
        "#     output = PrettyTable(['      Word       ', '       Tag      '])\n",
        "#     for w in heads:\n",
        "#         output.add_row([w, body[0][index] ])       \n",
        "#         index+=1  \n",
        "   \n",
        "#     #-------------------------------------\n",
        "#     outputText.configure(state='normal')\n",
        "#     outputText.delete('1.0', END)    \n",
        "#     outputText.insert(\"insert\", output) \n",
        "#     outputText.configure(state='disabled')\n",
        "#     #-------------------------------------\n",
        "\n",
        "#     return output\n",
        "\n",
        "# window = Tk()\n",
        "# window.title(\"Postagging\")\n",
        "# window.geometry('770x630')\n",
        "# title = '\\t\\tPostagging\\n BiLSTM + CRF with the cess_esp corpus from NLTK '\n",
        "\n",
        "# label= Label( text = title, background=\"white\", font = \"Consolas 18 bold\")\n",
        "# label.grid(column=0, row=0, pady=(10, 10), columnspan=2)\n",
        "\n",
        "# label= Label( text = \"  Input  \", background=\"white\", font = \"Consolas 12 bold\")\n",
        "# label.grid(column=0, row=1, pady=(10, 10))\n",
        "\n",
        "# btn = Button(window, text=\"  POS TAGGING >>  \",command=pos_tagging)\n",
        "# btn.grid(column=0, row=1, pady=(10, 10), columnspan=2 )\n",
        "\n",
        "# label= Label( text = \"  Output  \", background=\"white\", font = \"Consolas 12 bold\")\n",
        "# label.grid(column=1, row=1, pady=(10, 10))\n",
        "\n",
        "# inputText = Text(window,height=25, width=40, font = \"Consolas 12\")\n",
        "# inputText.grid(column=0, row=3, padx=(10,10))\n",
        "\n",
        "# outputText = Text(window,height=25, width=40, state='disabled', font = \"Consolas 12\")\n",
        "# outputText.grid(column=1, row=3, padx=(10,10))\n",
        "# outputText.tag_configure(\"center\", justify='center')\n",
        "\n",
        "# window.mainloop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG0SYOFaMK-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "15597ede-87ea-4e6e-e954-0b1355167c47"
      },
      "source": [
        "test_samples = [\n",
        "    \"Correr es importante para mi .\".split(),\n",
        "    \"El hombre bajo corre bajo el puente con bajo índice de adrenalina .\".split()\n",
        "]\n",
        "print(\"\\nTesting sentences:\\n\\n\", test_samples[0], \"\\n\", test_samples[1])\n",
        "\n",
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    \n",
        "    test_samples_X.append(s_int)\n",
        "\n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "sentences,words = test_samples_X.shape\n",
        "print(\"\\n----------------------------------------------------------------------------\\n\")\n",
        "print(\"\\nTesting sentences parsed to integer (matrix of \", sentences ,\" sentences X \", words ,\" words ):\\n\\n\")\n",
        "print(test_samples_X[0], \"\\n\")\n",
        "print(test_samples_X[1], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing sentences:\n",
            "\n",
            " ['Correr', 'es', 'importante', 'para', 'mi', '.'] \n",
            " ['El', 'hombre', 'bajo', 'corre', 'bajo', 'el', 'puente', 'con', 'bajo', 'índice', 'de', 'adrenalina', '.']\n",
            "\n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Testing sentences parsed to integer (matrix of  2  sentences X  149  words ):\n",
            "\n",
            "\n",
            "[16251 13938  5301 11186 17742 22591     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0] \n",
            "\n",
            "[ 4757  3698 14203 16394 14203  4757 10884 20216 14203 17601  9799     1\n",
            " 22591     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEctDGdwMK-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "83a34b23-96b7-48d1-bc66-8017554024ca"
      },
      "source": [
        "heads1 = test_samples[0]\n",
        "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
        "\n",
        "heads2 = test_samples[1]\n",
        "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
        "\n",
        "print(\"\\nTest results:\\n\\n\")\n",
        "print(tabulate(body1, headers=heads1), \"\\n\")\n",
        "print(tabulate(body2, headers=heads2), \"\\n\")\n",
        "\n",
        "## postagging Freeling 4.1\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
        "## DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
        "\n",
        "\n",
        "## pos tagger Stanford NLP\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
        "## da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test results:\n",
            "\n",
            "\n",
            "Correr    es     importante    para    mi     .\n",
            "--------  -----  ------------  ------  -----  -------\n",
            "ncfp000   spcms  ncms000       aq0ms0  sps00  np0000o \n",
            "\n",
            "El      hombre    bajo     corre    bajo    el       puente    con      bajo    índice    de      adrenalina    .\n",
            "------  --------  -------  -------  ------  -------  --------  -------  ------  --------  ------  ------------  --------\n",
            "dp3cs0  ncms000   vsip3s0  vmsp3s0  sps00   np0000o  cc        np0000o  Fc      da0fp0    dn0cp0  ncfp000       pr0cn000 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOFRH3NyMK-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}